##Техники Jacknife(складной нож) и bootstrap
#
#Для чего нужен Jacknife?
#
#1)Jacknife помогает исправлять точечные оценки
#2)Искать оценки дисперсии многих оценок
#
#Пример jacknife:
#Допустим x[0;Z]
#у нас есть выборка [x...xn]
#
#Мы хотим найти Математическое ожидание X 
#Математическое ожидание X - это математически ожидаемое значение X
#Оценкой мат ожидания будет выборочное среднее summ(xi)/n
#
#Математическое ожидание - это характеристика распределения
#
#Мат.ожидание дискретного X будет равно Summ(pxj*xj),где xj наблюдение, pxj - вероятность xj
#
#Истиное мат ожидание - это произведение вероятностей на наблюдения, а оценка мат ожидания
#это наше среднее по выборке, где количество разных наблюдений деленое на общее количество
#наблюдений выступает в роли оценки вероятности
#
#Например в выборке 5555511122, оценка мат ожидания будет 5*5/10+3*1/10 +2*2/10 =  3.2
#
#Пример, когда замена вероятностей на частоты может давать неверные результаты:
#Ситуация оценки дисперсии случайной величины
#
#Дисперсия это сумма мат ожиданий квадрата отклонения Х от мат ожидания X
#то есть V(x) = summ(px*(xj - E(x))^2)
#
#Оценка дисперсии это замена px на частоты 
#S = summ((xj - E(x))^2/n), но так как мы не знаем реальное мат ожидание x
#мы подставляем в эту же формулу оценку мат ожидания x, которая равна xср и получаем
#
#S = summ((xj - (xср))^2/n)
#
#если вместо истиного мат ожидания подставлять оценку мат ожидания по выборке - оценка будет
#"плохой"
#Что не так с этой оценкой? 
#мат ожидание нашей оценки, не равно дисперсии случайно величины
#
#Мат ожидание выборки = истиная дисперсия * (n-1)/n
#соответственно, чтобы узнать истиную дисперсию мы делим нашу оценку на n-1
#
#Jackknife помогает автоматически исправлять оценку дисперсии если она смещенная:
#
#Допустим у нас есть X и мы хотим оценить какой-то параметр O, а у нас есть O'(выборочный),
#который не совпадает с O 
#Запишем мат ожидание выборочное, как 
#Мат ожидание O' = O + a/n + b/n^2 + c/n^3 +... 
#jackknife позволяет избавиться от a/n
#
#Допустим у нас есть x[x1...xn]
#
#O'i  - это значение на выборке без какого-то значение xi 
#посчитаем среднее значение O'i = summ(O'i/n)
#
#Итак, у нас имеется выборка [X1...Xn], и какая-то оценка ??^ параметра ??. 
#У нас есть основания полагать, что наша оценка смещена. Мы предполагаем, 
#что E(??^)=??+??n+??n2+... 
#
#Из предыдущего задания вы знаете мат.ожидание ??^(i).
#
#Давайте теперь внимательно посмотрим на мат.ожидание ???? (на всякий случай, напомним: 
#????=???ni=1??^(i)n)
#
#Используя следующие факты про мат.ожидание:
#  
#  E(c???X)=c???E(X) 
#  
#  E(X+Y)=E(X)+E(Y) 
# 
#  (где c – это какая-то константа, а X и Y - случайные переменные), 
#  
#  и совсем простой факт про сумму: ???ni=1(a+b+c)=???ni=1(a)+???ni=1(b)+???ni=1(c)=na+nb+nc , 
#(если a, b и c не зависят от i),
#  
#  найдите мат.ожидание ???? (игнорируя составляющие ошибки дальше квадратичной)
#  
#  P.S. обязательно попробуйте решить это задание, и вне зависимости от степени успеха – 
#внимательно прочитайте решение (будет доступно после отправки).
#
#Чтобы исправить смещение оценки с помощью jackknife:
#1)Хотим оценить какую-то статистику по случайной выборке
#2)На основании выборки получаем оценочную статистику O' = T(x1...xn), где Т - некая функция
#3)Но функция может быть смещенной
#4)Тогда O = O' + bias
#5)Тогда мы сгенерируем много(n) выборок из нашей O'i = T(x1...xn без xi)
#6)и посчитаем среднее этих значений O'ср
#7)bias(jack) = (n-1)*(O' - O'ср) 
#8)Тогда Ojack = O' - bias(jack) (оценка по методу jackknife)
#

JN_bias_correction <- function(x, estimator) {
  estimator(x)-(mean(sapply(seq_along(x),
                            function(i) estimator(x[-i])))-estimator(x))*(length(x)-1)
}

library(ggplot2)

bad_var_estimator <- function(x) {
  n <- length(x)
  return(var(x)*(n-1)/n)
}

JN_bias_correction <- function(x, estimator){
  n <- length(x)
  theta_stars <- vector("numeric",n)
  ind <- c(1:n)
  
  for(i in ind) {
    sample <- x[ind != i]
    theta_stars[i] <- estimator(sample)
  }
  
  theta_hat <- estimator(x)
  theta_dot <- mean(theta_stars)
  
  bias_jack <- (theta_dot - theta_hat)*(n-1)
  theta_hat_jack <- theta_hat - bias_jack
  return(theta_hat_jack)
}
start <- 3

sample_sizes <- c(start:50)
test <- 100

results_good <- sample_sizes
results_bad <- sample_sizes
results_corrected <- sample_sizes

for (n in sample_sizes){
  samples <- matrix (rnorm(n*test), n)
  
  good_estimations <- apply (samples, 2, var)
  bad_estimations <- apply (samples, 2, var)
  corrected_estimations <- apply(samples, JN_bias_correction, estimator = bad_var_estimator)
  
  results_good[n-start+1] <- mean(good_estimations)
  results_bad[n-start+1] <- mean(bad_estimations)
  results_corrected[n-start+1] <- mean(corrected_estimations)
}

df <- data.frame(x = rep(sample_sizes,3),
                 y = c(results_good,results_bad, results_corrected),
                 gr = factor(rep(1:3, each = length(sample_sizes))),
                 labels = c("results_good","results_bad","results_corrected"))

ggplot(df, aes(x, y, col = gr))+
  geom_jitter()
#
#Допустим у нас есть распределение от 0 до X, и у нас есть выборка из него
#Как оценить абсолютное максимальное значение, имея на руках выборку, максимальное
#значение в выборке будет смещенным относительно абсолютного максимального значения
#Чтобы посчитать абсолютное максимальное значение можно использовать поправку Jackknife
#
#С увеличение количества выборки значение максимального роста тараканов приближается 
#к идеальному
#
###Метод Bootstrap
#Когда необходимо оценить доверительный интервал или дисперсию применяется Bootstrap
#
#Допустим у нас есть генеральная совокупность, и мы взяли из неё выборку.
#Например рост 20 студентов, мы поверили средний рост 20 студентов и хотим узнать
#как распределено T(x) если бы мы брали много выборок, где Т это какая-либо функция
#
#По классическому подходу:
#Мы делали предположение Н0 о генеральной совокупности и проверяли его
#Считали доверительные интервалы и принимали или отвергали Н0
#
#Что если мы не можем предположить нормальность распределения
#
#По методу bootstrap:
#Мы берем нашу выборку и строим по ней гистограмму, в какой-то мере распределение нашей 
#выборки должно быть таким же как распределение в генеральной совокупности, то есть 
#мы подменяем предположении о нормальном распределении в генеральной совокупности
#на то, что распределение в генеральной совокупности распределение такое же, как в нашей
#выборке
#
#Перцентильный Бутстрап
#допустим у нас есть x[x1...xn]
#1)мы посчитали xср
#2)мы строим гистограмму x и предполагаем, что она распределяется так же, как генеральная 
#3)совокупность.
#4)делаем выборки(с повторениями) из нашей выборки и генерируем много таких подвыборок
#5)Считаем xiср каждой выборки
#6)Строим распределение xiср и посчитать для него доверительный интервал
#
#Базовый бутстрап
#В данном случае мы принимаем нашу выборку за генеральную совокупность и берем из неё 
#выборки
#и получаем вероятность, что m нашей выборки (которая генеральная совокупность)
#попадания этого среднего в распределение средних от подвыборок(бутстрапированных выборок)
#
library(ggplot2)

X_bar = 10
X_barstar = rnorm(70, X_bar , 1)

ggplot()+
  geom_histogram(aes(X_barstar),binwidth = 0.1)+
  geom_histogram(aes(X_bar-X_barstar),binwidth = 0.1)+
  geom_vline(xintercept = quantile(X_barstar, 0.95), col = 'red')+
  geom_vline(xintercept = quantile(X_barstar, 0.05), col = 'red')+
  geom_vline(xintercept = quantile(X_bar-X_barstar, 0.95), col = 'green')+
  geom_vline(xintercept = quantile(X_bar-X_barstar, 0.05), col = 'green')+
  theme_bw()
#
#Bootstrap бывает разных видов, можно изучать долго
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#